# data_preprocessing.py (script de formatage et de nettoyage)

import pandas as pd
from pathlib import Path # Pour une meilleure gestion des chemins
import sys

import config

# Ajout du chemin du projet au PYTHONPATH si n√©cessaire pour importer config
# Cela permet d'utiliser BASE_DIR de config.py pour les chemins des fichiers
# Pour l'ex√©cution standalone de ce script, c'est mieux de d√©finir les chemins directement
# Ou de s'assurer que src/config.py est importable si ce script fait partie du package.
# Pour la simplicit√© ici, je vais d√©finir les chemins directement.

# Assumons que ce script est dans le r√©pertoire 'data/' ou √† la racine du projet
# Si ce script est dans 'data/', changez '..' en '.' ou ajustez selon l'emplacement r√©el.
# Si ce script est √† la racine du projet, alors 'data/' et 'models/' sont des sous-dossiers.
# Pour le moment, je vais le mettre √† la racine comme votre arborescence sugg√®re qu'il pourrait √™tre lanc√© de l√†,
# et config.py g√®re les chemins relatifs √† BASE_DIR.

# R√©pertoire de base du projet (ajustez si votre script n'est pas √† la racine)


def preprocess_lol_data():
    """
    Charge les donn√©es brutes, les nettoie et les restructure pour l'entra√Ænement du mod√®le.
    Sauvegarde le dataset nettoy√© dans le dossier data/.
    """
    print("üöÄ D√©marrage du pr√©traitement des donn√©es League of Legends...")

    # 1. Charger les donn√©es brutes
    try:
        # Colonnes int√©ressantes du dataset brut
        columns_to_keep = ["gameid", "participantid", "pick1", "pick2", "pick3", "pick4", "pick5", "result"]
        df = pd.read_csv(config.RAW_DATA_PATH, usecols=columns_to_keep)
        print(f"‚úÖ Donn√©es brutes charg√©es depuis '{config.RAW_DATA_PATH}' : {len(df)} lignes.")
    except FileNotFoundError:
        print(f"‚ùå Erreur : Le fichier de donn√©es brutes '{config.RAW_DATA_PATH}' n'a pas √©t√© trouv√©.")
        print("Assurez-vous que le chemin est correct et que le fichier existe.")
        sys.exit(1) # Quitter le script en cas d'erreur fatale

    # 2. Filtrer les participants (participantid 100 pour √âquipe 1, 200 pour √âquipe 2)
    df_filtered = df[df["participantid"].isin([100, 200])].copy() # Utiliser .copy() pour √©viter SettingWithCopyWarning
    df_filtered = df_filtered.drop(columns=["participantid"])
    df_filtered = df_filtered.reset_index(drop=True)
    print(f"üìä Donn√©es filtr√©es pour les √©quipes 100 et 200 : {len(df_filtered)} lignes.")

    # 3. Restructurer le dataset pour avoir une ligne par match
    print("üîÑ Restructuration du dataset (une ligne par match)...")
    df_restructured = restructure_dataset(df_filtered)
    print(f"‚úÖ Dataset restructur√© : {len(df_restructured)} matchs.")

    # 4. Nettoyage : Suppression des lignes avec des valeurs manquantes (champions non renseign√©s)
    df_clean = df_restructured.dropna()
    print(f"üßπ Suppression des lignes avec valeurs manquantes : {len(df_restructured) - len(df_clean)} lignes supprim√©es.")
    print(f"Total de lignes apr√®s nettoyage : {len(df_clean)}.")
    if len(df_restructured) > 0:
        print(f"Pourcentage de donn√©es conserv√©es : {len(df_clean)/len(df_restructured)*100:.1f}%")

    # 5. V√©rifications et affichage des statistiques
    print("\n--- V√©rifications du dataset nettoy√© ---")
    print("Valeurs manquantes apr√®s nettoyage :")
    print(df_clean.isnull().sum())

    all_champions = set()
    for col in ['team1_pick1', 'team1_pick2', 'team1_pick3', 'team1_pick4', 'team1_pick5',
               'team2_pick1', 'team2_pick2', 'team2_pick3', 'team2_pick4', 'team2_pick5']:
        all_champions.update(df_clean[col].unique())
    print(f"Nombre de champions uniques : {len(all_champions)}")
    print(f"Exemples de champions : {list(all_champions)[:10]}")

    print("Distribution des r√©sultats ('team1_wins') :")
    print(df_clean['team1_wins'].value_counts())

    duplicates_in_picks = df_clean.apply(check_duplicate_champions, axis=1)
    if duplicates_in_picks.sum() > 0:
        print(f"‚ö†Ô∏è Attention : {duplicates_in_picks.sum()} lignes contiennent des champions dupliqu√©s dans la m√™me √©quipe.")
        print("Cela pourrait indiquer une anomalie dans les donn√©es brutes ou une logique √† affiner si cela n'est pas attendu.")
    else:
        print("‚úÖ Aucune composition d'√©quipe avec des champions dupliqu√©s trouv√©e.")

    # 6. Sauvegarder le dataset nettoy√©
    df_clean.to_csv(config.CLEAN_DATA_PATH, index=False)
    print(f"\nüíæ Dataset nettoy√© sauvegard√© dans : '{config.CLEAN_DATA_PATH}'")
    print("\nüéâ Pr√©traitement des donn√©es termin√© avec succ√®s !")


def restructure_dataset(df: pd.DataFrame) -> pd.DataFrame:
    """Transforme le dataset pour avoir une ligne par match, en combinant les picks des deux √©quipes."""
    matches = []
    
    # Grouper par gameid
    for game_id in df['gameid'].unique():
        game_data = df[df['gameid'] == game_id]
        
        if len(game_data) == 2:  # V√©rifier qu'on a bien 2 √©quipes (participantid 100 et 200)
            team1 = game_data.iloc[0] # Premi√®re ligne correspond √† team 100 (ou 200, l'ordre n'est pas garanti par gameid)
            team2 = game_data.iloc[1] # Deuxi√®me ligne

            # Si l'ordre n'est pas garanti par le tri initial, il faut s'assurer que team1_wins correspond bien √† team1_picks
            # Assumons que la premi√®re ligne est Team 1 et la deuxi√®me Team 2 pour la coh√©rence
            # avec la cr√©ation de team1_wins ci-dessous.
            # Si 'participantid' √©tait toujours 100 pour la 1√®re ligne et 200 pour la 2√®me apr√®s le filtre,
            # alors l'ordre est bon. Sinon, il faudrait trier ou v√©rifier 'participantid' ici.
            
            # Cr√©er une ligne avec les deux compositions et le r√©sultat
            match_row = {
                'team1_pick1': team1['pick1'],
                'team1_pick2': team1['pick2'],
                'team1_pick3': team1['pick3'],
                'team1_pick4': team1['pick4'],
                'team1_pick5': team1['pick5'],
                'team2_pick1': team2['pick1'],
                'team2_pick2': team2['pick2'],
                'team2_pick3': team2['pick3'],
                'team2_pick4': team2['pick4'],
                'team2_pick5': team2['pick5'],
                'team1_wins': team1['result']  # 1 si team1 gagne, 0 sinon (bas√© sur le 'result' de la premi√®re ligne)
            }
            matches.append(match_row)
    
    return pd.DataFrame(matches)

def check_duplicate_champions(row):
    """V√©rifie si des champions sont dupliqu√©s dans une m√™me composition d'√©quipe."""
    team1_picks = [row[f'team1_pick{i}'] for i in range(1, 6)]
    team2_picks = [row[f'team2_pick{i}'] for i in range(1, 6)]
    # Retourne True si des doublons sont trouv√©s dans l'une ou l'autre √©quipe
    return len(set(team1_picks)) != 5 or len(set(team2_picks)) != 5

if __name__ == "__main__":
    preprocess_lol_data()