# src/train.py (avec RandomizedSearchCV pour le r√©glage des hyperparam√®tres)

import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import config
from scipy.stats import randint, uniform # Pour les distributions al√©atoires des hyperparam√®tres

def transform_to_composition_format(df: pd.DataFrame) -> pd.DataFrame:
    """
    Transforme le DataFrame en format sym√©trique pour √©viter le biais de position.
    """
    print("üîÑ Transformation des donn√©es au format sym√©trique...")
    
    pick_cols = [f'team{t}_pick{i}' for t in [1, 2] for i in range(1, 6)]
    all_champions = pd.unique(df[pick_cols].values.ravel('K'))
    all_champions = [c for c in all_champions if pd.notna(c)]
    print(f"üåç Nombre total de champions uniques trouv√©s : {len(all_champions)}")

    # Cr√©er les colonnes pour les deux √©quipes (A et B au lieu de team1/team2)
    feature_column_names = [f"teamA_{c}" for c in all_champions] + \
                           [f"teamB_{c}" for c in all_champions]
    
    # Cr√©er le DataFrame final qui contiendra les donn√©es originales + les donn√©es invers√©es
    all_rows = []
    
    for index, row in df.iterrows():
        team1_picks = [row[f'team1_pick{i}'] for i in range(1, 6)]
        team2_picks = [row[f'team2_pick{i}'] for i in range(1, 6)]
        
        # Version originale : team1 -> teamA, team2 -> teamB
        row_original = pd.Series(0, index=feature_column_names)
        for champion in team1_picks:
            if pd.notna(champion):
                row_original[f"teamA_{champion}"] = 1
        for champion in team2_picks:
            if pd.notna(champion):
                row_original[f"teamB_{champion}"] = 1
        row_original[config.TARGET_COLUMN] = row[config.TARGET_COLUMN]
        all_rows.append(row_original)
        
        # Version invers√©e : team2 -> teamA, team1 -> teamB
        row_inverted = pd.Series(0, index=feature_column_names)
        for champion in team2_picks:
            if pd.notna(champion):
                row_inverted[f"teamA_{champion}"] = 1
        for champion in team1_picks:
            if pd.notna(champion):
                row_inverted[f"teamB_{champion}"] = 1
        # Inverser le label : si team1 gagnait (1), maintenant team2 est en teamA donc 0
        row_inverted[config.TARGET_COLUMN] = 1 - row[config.TARGET_COLUMN]
        all_rows.append(row_inverted)
    
    df_encoded = pd.DataFrame(all_rows)
    print(f"üìà Dataset augment√© : {len(df)} -> {len(df_encoded)} exemples")
    
    return df_encoded

def train_model():
    """
    Fonction principale pour entra√Æner et sauvegarder le mod√®le.
    """
    print("üöÄ D√©marrage de l'entra√Ænement...")

    try:
        df_raw = pd.read_csv(config.CLEAN_DATA_PATH)
        print(f"‚úÖ Donn√©es brutes charg√©es avec succ√®s : {len(df_raw)} lignes.")
    except FileNotFoundError:
        print(f"‚ùå Erreur : Le fichier {config.CLEAN_DATA_PATH} n'a pas √©t√© trouv√©.")
        print("Veuillez d'abord ex√©cuter le script de pr√©traitement des donn√©es (`data_preprocessing.py`).")
        return

    df_transformed = transform_to_composition_format(df_raw)
    
    X = df_transformed.drop(columns=[config.TARGET_COLUMN])
    y = df_transformed[config.TARGET_COLUMN]

    # Sauvegarder les noms des colonnes pour la pr√©diction future
    # Cela doit √™tre fait AVANT de diviser les donn√©es pour la recherche d'hyperparam√®tres
    # car les colonnes doivent correspondre exactement pour la pr√©diction.
    joblib.dump(X.columns, config.MODELS_DIR / 'model_columns.joblib')
    print(f"üî¢ Le nombre de features est maintenant de : {X.shape[1]}")
    print(f"üëÄ Aper√ßu des colonnes d'entra√Ænement (premi√®res 5) : {list(X.columns[:5])}")


    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    print(f"üìä Donn√©es divis√©es : {len(X_train)} pour l'entra√Ænement, {len(X_test)} pour le test.")

    # --- Configuration de la recherche al√©atoire des hyperparam√®tres ---
    print("\n‚öôÔ∏è D√©marrage de la recherche al√©atoire des hyperparam√®tres pour RandomForestClassifier...")

    # D√©finir le mod√®le de base pour la recherche
    rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)

    # D√©finir les distributions des hyperparam√®tres √† √©chantillonner
    # Tu peux ajuster ces plages en fonction de tes observations initiales ou de la complexit√© attendue
    param_distributions = {
        'n_estimators': randint(100, 500),         # Nombre d'arbres entre 100 et 499
        'max_depth': [None, 10, 20, 30, 40, 50], # Profondeur maximale (None pour illimit√©e)
        'min_samples_split': randint(2, 20),       # Minimum d'√©chantillons pour une division (entre 2 et 19)
        'min_samples_leaf': randint(1, 10),        # Minimum d'√©chantillons par feuille (entre 1 et 9)
        'max_features': ['sqrt', 'log2', 0.5, 0.7, 0.9, 1.0] # Strat√©gies pour le nombre de features
    }

    # Initialiser RandomizedSearchCV
    # n_iter: nombre de combinaisons d'hyperparam√®tres √† √©chantillonner
    # cv: nombre de plis pour la validation crois√©e
    # scoring: m√©trique d'√©valuation (accuracy est un bon d√©but pour la classification √©quilibr√©e)
    # verbose: niveau de d√©tail des logs
    random_search = RandomizedSearchCV(estimator=rf_base,
                                       param_distributions=param_distributions,
                                       n_iter=5, # Choisir un nombre d'it√©rations raisonnable (par exemple, 50 √† 100)
                                       cv=5,       # 5 plis de validation crois√©e
                                       n_jobs=-1,  # Utiliser tous les c≈ìurs disponibles
                                       verbose=2,  # Afficher les progr√®s
                                       scoring='accuracy', # ou 'f1', 'roc_auc' si d√©s√©quilibr√©
                                       random_state=42)

    # Lancer la recherche
    random_search.fit(X_train, y_train)

    print("\n‚úÖ Recherche al√©atoire des hyperparam√®tres termin√©e.")
    print(f"Meilleurs hyperparam√®tres trouv√©s : {random_search.best_params_}")
    print(f"Meilleure pr√©cision en validation crois√©e : {random_search.best_score_:.4f}")

    # Utiliser le meilleur mod√®le trouv√© par la recherche
    model = random_search.best_estimator_
    # --- Fin de la configuration de la recherche al√©atoire ---

    # 5. √âvaluer le mod√®le (le meilleur mod√®le trouv√© par la recherche)
    print("\nüìà √âvaluation du mod√®le final (avec les meilleurs hyperparam√®tres)...")
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\nPr√©cision (Accuracy) sur l'ensemble de test : {accuracy:.4f}")
    print("\nRapport de classification :\n", classification_report(y_test, y_pred))
    print("Matrice de confusion :\n", confusion_matrix(y_test, y_pred))

    # 6. Sauvegarder le mod√®le (le meilleur mod√®le)
    print(f"\nüíæ Sauvegarde du mod√®le entra√Æn√© dans : {config.MODEL_PATH}")
    joblib.dump(model, config.MODEL_PATH)

    print("\nüéâ Processus d'entra√Ænement termin√© avec succ√®s !")

if __name__ == "__main__":
    train_model()